{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple linear regression using Hilbert transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Written by Abirlal Metya, Panini Dasgupta, Manmeet Singh (25/12/2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.signal import hilbert, chirp\n",
    "import hilbert_data1_panini_20CRV33\n",
    "import datetime\n",
    "\n",
    "\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train,_ = hilbert_data1_panini_20CRV33.data_hilbert(datetime.datetime(1979,1,1),datetime.datetime(2008,12,31))\n",
    "x_test,y_test,_ = hilbert_data1_panini_20CRV33.data_hilbert(datetime.datetime(1974,6,1),datetime.datetime(1978,3,16))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape,y_train.shape,x_test.shape,y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt#plot the first image in the dataset\n",
    "from scipy.signal import hilbert\n",
    "plt.figure(figsize=[20,5])\n",
    "#plt.imshow(xtrain[1,:,:,0])\n",
    "plt.plot(np.arange(100),x_train.iloc[0:100,0],'-r')\n",
    "plt.plot(np.arange(100),np.imag(hilbert(x_train.iloc[:,0])[0:100]),':g')\n",
    "plt.plot(np.arange(100),x_train.iloc[0:100,12],'--b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_train.iloc[1:200,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = linear_model.LinearRegression()\n",
    "model = lm.fit(x_train.values,y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lm.predict(x_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(lm.score(x_train.values,y_train.values))**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.corrcoef(predictions[:,0],y_test.values[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot different columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS(y_train, x_train).fit()\n",
    "predictions = model.predict(x_train) # make the predictions by the model\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test3 = hilbert_data1_panini_20CRV33.data_pres(datetime.datetime(1905,1,1),datetime.datetime(2015,12,31))\n",
    "predictions_test = lm.predict(x_test3.values)\n",
    "predict_tot = predictions_test#/predictions.std()\n",
    "rmm1_predict = pd.DataFrame(predict_tot,index=x_test3.index)\n",
    "rmm1_predict.to_csv('rmm1_MLR_36.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "sc3 = MinMaxScaler()\n",
    "sc5 = MinMaxScaler()\n",
    "\n",
    "sc5.fit(x_train[:])\n",
    "\n",
    "#test_x3 =  sc5.transform(x_test3[:])\n",
    "train_x = sc5.transform(x_train[:])\n",
    "test_x  = sc5.transform(x_test[:])\n",
    "\n",
    "\n",
    "sc3.fit(y_train[:])\n",
    "\n",
    "train_y = sc3.transform(y_train)\n",
    "test_y  = sc3.transform(y_test)\n",
    "\n",
    "train_x.max(),test_x.max(),train_y.max(),test_y.max()\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "\n",
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=36, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(80, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(80, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "\n",
    "history = model.fit(train_x, train_y, validation_data=(test_x,test_y),epochs=30, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'],'-*',label ='train')\n",
    "plt.plot(history.history['val_loss'],'-*',label ='test')\n",
    "plt.ylabel('MAE')\n",
    "plt.xlabel('No of Epochs')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict1   = model.predict(train_x)\n",
    "yy_train   = sc3.inverse_transform(predict1)\n",
    "yy_train   = yy_train/yy_train.std()\n",
    "train_corr = np.corrcoef(yy_train[:,0],train_y[:,0])[0,1]\n",
    "\n",
    "print(\"training shape = \");print(predict1.shape)\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize = (12,4))\n",
    "\n",
    "ax[0].plot(yy_train[:,0],train_y,'.')\n",
    "\n",
    "ax[0].set_title('corr = %f'%train_corr)\n",
    "\n",
    "bins = np.linspace(-4.0,4.0,41)\n",
    "\n",
    "ax[1].hist(y_train.rmm1,bins,density=True,alpha=0.5,label='observed')\n",
    "ax[1].hist(yy_train,bins,density=True,alpha=0.5,label='modeled');\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict2  = model.predict(test_x)\n",
    "yy_test   = sc3.inverse_transform(predict2)\n",
    "yy_test   = yy_test/yy_test.std()\n",
    "test_corr = np.corrcoef(yy_test[:,0],test_y[:,0])[0,1]\n",
    "\n",
    "print(\"test shape = \");print(predict2.shape)\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize = (12,4))\n",
    "\n",
    "ax[0].plot(yy_test[:,0],test_y,'.')\n",
    "\n",
    "ax[0].set_title('corr = %f'%test_corr)\n",
    "\n",
    "bins = np.linspace(-4.0,4.0,41)\n",
    "\n",
    "ax[1].hist(y_test.rmm1,bins,density=True,alpha=0.5,label='observed')\n",
    "ax[1].hist(yy_test,bins,density=True,alpha=0.5,label='modeled');\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMM2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,_,y_train = hilbert_data1_panini_20CRV33.data_hilbert(datetime.datetime(1979,1,1),datetime.datetime(2008,12,31))\n",
    "x_test,_,y_test = hilbert_data1_panini_20CRV33.data_hilbert(datetime.datetime(1974,6,1),datetime.datetime(1978,3,16))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = linear_model.LinearRegression()\n",
    "model = lm.fit(x_train.values,y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lm.predict(x_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(lm.score(x_train.values,y_train.values))**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(predictions[:,0],y_test.values[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS(y_train, x_train).fit()\n",
    "predictions = model.predict(x_train) # make the predictions by the model\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test3 = hilbert_data1_panini_20CRV33.data_pres(datetime.datetime(1905,1,1),datetime.datetime(2015,12,31))\n",
    "predictions_test = lm.predict(x_test3.values)\n",
    "predict_tot = predictions_test#/predictions.std()\n",
    "rmm2_predict = pd.DataFrame(predict_tot,index=x_test3.index)\n",
    "rmm2_predict.to_csv('rmm2_MLR_36.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "sc3 = MinMaxScaler()\n",
    "sc5 = MinMaxScaler()\n",
    "\n",
    "sc5.fit(x_train[:])\n",
    "\n",
    "#test_x3 =  sc5.transform(x_test3[:])\n",
    "train_x = sc5.transform(x_train[:])\n",
    "test_x  = sc5.transform(x_test[:])\n",
    "\n",
    "\n",
    "sc3.fit(y_train[:])\n",
    "\n",
    "train_y = sc3.transform(y_train)\n",
    "test_y  = sc3.transform(y_test)\n",
    "\n",
    "train_x.max(),test_x.max(),train_y.max(),test_y.max()\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "\n",
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=36, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(80, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(80, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "\n",
    "history = model.fit(train_x, train_y, validation_data=(test_x,test_y),epochs=30, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict1   = model.predict(train_x)\n",
    "yy_train   = sc3.inverse_transform(predict1)\n",
    "yy_train   = yy_train/yy_train.std()\n",
    "train_corr = np.corrcoef(yy_train[:,0],train_y[:,0])[0,1]\n",
    "\n",
    "print(\"training shape = \");print(predict1.shape)\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize = (12,4))\n",
    "\n",
    "ax[0].plot(yy_train[:,0],train_y,'.')\n",
    "\n",
    "ax[0].set_title('corr = %f'%train_corr)\n",
    "\n",
    "bins = np.linspace(-4.0,4.0,41)\n",
    "\n",
    "ax[1].hist(y_train.rmm2,bins,density=True,alpha=0.5,label='observed')\n",
    "ax[1].hist(yy_train,bins,density=True,alpha=0.5,label='modeled');\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict2  = model.predict(test_x)\n",
    "yy_test   = sc3.inverse_transform(predict2)\n",
    "yy_test   = yy_test/yy_test.std()\n",
    "test_corr = np.corrcoef(yy_test[:,0],test_y[:,0])[0,1]\n",
    "\n",
    "print(\"test shape = \");print(predict2.shape)\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize = (12,4))\n",
    "\n",
    "ax[0].plot(yy_test[:,0],test_y,'.')\n",
    "\n",
    "ax[0].set_title('corr = %f'%test_corr)\n",
    "\n",
    "bins = np.linspace(-4.0,4.0,41)\n",
    "\n",
    "ax[1].hist(y_test.rmm2,bins,density=True,alpha=0.5,label='observed')\n",
    "ax[1].hist(yy_test,bins,density=True,alpha=0.5,label='modeled');\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
