{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked Long-term Short-term memory network (Stacked-LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Written by Abirlal Metya, Panini Dasgupta, Manmeet Singh (19/12/2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout,LSTM,Dense\n",
    "from keras.layers import LeakyReLU\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime\n",
    "import hilbert_data1_jgrjd_20CRV3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test and Train Splitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train,_ = hilbert_data1_jgrjd_20CRV3.data_hilbert(datetime.datetime(1979,1,1),datetime.datetime(2008,12,31))\n",
    "x_test,y_test,_ = hilbert_data1_jgrjd_20CRV3.data_hilbert(datetime.datetime(1974,6,1),datetime.datetime(1978,3,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10839, 24) (10839, 1) (1266, 24) (1266, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmm1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1979-04-30</th>\n",
       "      <td>-0.823292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-05-01</th>\n",
       "      <td>-0.412913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-05-02</th>\n",
       "      <td>0.021600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-05-03</th>\n",
       "      <td>0.424877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-05-04</th>\n",
       "      <td>0.745713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                rmm1\n",
       "date                \n",
       "1979-04-30 -0.823292\n",
       "1979-05-01 -0.412913\n",
       "1979-05-02  0.021600\n",
       "1979-05-03  0.424877\n",
       "1979-05-04  0.745713"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_train.shape,y_train.shape,x_test.shape,y_test.shape)\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Historical pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test3 = hilbert_data1_jgrjd_20CRV3.data_pres(datetime.datetime(1946,1,1),datetime.datetime(2015,12,31))\n",
    "x_test3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_test3.iloc[:,0],label = 'total _period')\n",
    "plt.plot(x_train.iloc[:,0], label = 'train')\n",
    "plt.plot(x_test.iloc[:,0], label = 'test')\n",
    "plt.legend()\n",
    "plt.ylabel('RMM1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "sc3 = MinMaxScaler()\n",
    "sc5 = MinMaxScaler()\n",
    "\n",
    "sc5.fit(x_test3[:])\n",
    "\n",
    "test_x3 =  sc5.transform(x_test3[:])\n",
    "train_x = sc5.transform(x_train[:])\n",
    "test_x  = sc5.transform(x_test[:])\n",
    "\n",
    "\n",
    "sc3.fit(y_train[:])\n",
    "\n",
    "train_y = sc3.transform(y_train)\n",
    "test_y  = sc3.transform(y_test)\n",
    "\n",
    "train_x.max(),test_x.max(),test_x3.max(),train_y.max(),test_y.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In RNN we have to choose a window. Here we choose first 120 points as predictor and next RMM value as predicted. That means RMM will be fitted using previous 120 time steps's pressure of every point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split the sequence data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequence(window,x,*args):\n",
    "    xout  = []\n",
    "    for i in range(window,len(x)):\n",
    "        xout.append(x[i-window:i,:])\n",
    "    \n",
    "    xout = np.array(xout)\n",
    "    xout = np.reshape(xout,(xout.shape[0],xout.shape[1],xout.shape[2]))\n",
    "        \n",
    "    if np.any(len(args)):\n",
    "        for y in args:\n",
    "            yout = []\n",
    "            for i in range(window,len(y)):\n",
    "                yout.append(y[i,0])\n",
    "            yout = np.array(yout)\n",
    "            yout = yout.reshape(yout.shape[0])\n",
    "    else:\n",
    "        yout = [] \n",
    "    \n",
    "    return xout,yout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 120\n",
    "xtrain , ytrain = split_sequence(window,train_x,train_y)\n",
    "xtest , ytest = split_sequence(window,test_x,test_y)\n",
    "xtest3,_ = split_sequence(window, test_x3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cut the data according to batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_b =100 \n",
    "\n",
    "print(x_test3.shape)\n",
    "te3_lc = ((len(x_test3)-window)//par_b)*par_b\n",
    "\n",
    "xtest3 = xtest3[:te3_lc,:,:]\n",
    "print(xtest3.shape)\n",
    "\n",
    "x_test3.iloc[window:window+te3_lc,:].index\n",
    "## THis perid data will be available\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xtrain.shape,ytrain.shape,xtest.shape,ytest.shape)\n",
    "\n",
    "tr_lc = ((len(x_train)-window)//par_b)*par_b\n",
    "te_lc =  ((len(x_test)-window)//par_b)*par_b\n",
    "xtrain = xtrain[:tr_lc,:,:]\n",
    "ytrain = ytrain[:tr_lc]\n",
    "xtest = xtest[:te_lc,:,:]\n",
    "ytest = ytest[:te_lc]\n",
    "\n",
    "print(xtrain.shape,ytrain.shape,xtest.shape,ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the stacked-LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "\n",
    "regressor = Sequential()\n",
    "regressor.add(LSTM(90, batch_input_shape=(batch_size, xtrain.shape[1], xtrain.shape[2]), stateful=True, return_sequences=True))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(LSTM(90, batch_input_shape=(batch_size, xtrain.shape[1], xtrain.shape[2]), stateful=True, return_sequences=True))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(LSTM(90, batch_input_shape=(batch_size, xtrain.shape[1], xtrain.shape[2]), stateful=True, return_sequences=True))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(LSTM(90, batch_input_shape=(batch_size, xtrain.shape[1], xtrain.shape[2]), stateful=True))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(Dense(1,activation='linear'))\n",
    "regressor.compile(loss='mae', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "iteration = 5 \n",
    "for i in range(iteration):\n",
    "    print(i)\n",
    "    history = regressor.fit(xtrain, ytrain,validation_data= (xtest,ytest), epochs=1, batch_size=batch_size, verbose=1, shuffle=False)\n",
    "    regressor.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = regressor.fit(xtrain, ytrain,validation_data= (xtest,ytest), epochs=30, batch_size=batch_size, verbose=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'],'-*',label ='train')\n",
    "plt.plot(history.history['val_loss'],'-*',label ='test')\n",
    "plt.ylabel('MAE')\n",
    "plt.xlabel('No of Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('RMM1_history.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "regressor.fit(xtrain,ytrain,epochs=30,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram plot over train and test dataset\n",
    "To plot histogram real values of the model prediction is required. While model out put is normalized using Min-Max Scalar. So, inverse transform is required before histogrram with ytrain or smooth RMM component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predict train dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict1   = regressor.predict(xtrain,batch_size=batch_size)\n",
    "yy_train   = sc3.inverse_transform(predict1)\n",
    "yy_train   = yy_train/yy_train.std()\n",
    "train_corr = np.corrcoef(yy_train[:,0],ytrain)[0,1]\n",
    "\n",
    "print(\"training shape = \");print(predict1.shape)\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize = (12,4))\n",
    "\n",
    "ax[0].plot(yy_train[:,0],ytrain,'.')\n",
    "\n",
    "ax[0].set_title('corr = %f'%train_corr)\n",
    "\n",
    "bins = np.linspace(-4.0,4.0,41)\n",
    "\n",
    "ax[1].hist(y_train.rmm1,bins,density=True,alpha=0.5,label='observed')\n",
    "# plt.hist(rmm1.rmm1,bins=35,density=True,alpha=0.5,label='observed')\n",
    "ax[1].hist(yy_train,bins,density=True,alpha=0.5,label='modeled');\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predict test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict2  = regressor.predict(xtest,batch_size=batch_size)\n",
    "yy_test   = sc3.inverse_transform(predict2)\n",
    "yy_test   = yy_test/yy_test.std()\n",
    "test_corr = np.corrcoef(yy_test[:,0],ytest)[0,1]\n",
    "\n",
    "print(\"test shape = \");print(predict2.shape)\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize = (12,4))\n",
    "\n",
    "ax[0].plot(yy_test[:,0],ytest,'.')\n",
    "\n",
    "ax[0].set_title('corr = %f'%test_corr)\n",
    "\n",
    "bins = np.linspace(-4.0,4.0,41)\n",
    "\n",
    "\n",
    "ax[1].hist(y_test.rmm1,bins,density=True,alpha=0.5,label='observed')\n",
    "# plt.hist(rmm1.rmm1,bins=35,density=True,alpha=0.5,label='observed')\n",
    "ax[1].hist(yy_test,bins,density=True,alpha=0.5,label='modeled');\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dff = pd.read_csv('/home/cccr/supriyo/panini/data/full_data_nn.txt',index_col='date')\n",
    "rmm = dff[['rmm1']]\n",
    "rmm.index = pd.to_datetime(rmm.index)\n",
    "rmm1 = rmm[rmm.index.year >= 1979]\n",
    "rmm2 = rmm[rmm.index.year < 1978]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction over long time period (1946-2008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict3 = regressor.predict(xtest3,batch_size=batch_size)\n",
    "predict3 = sc3.inverse_transform(predict3)\n",
    "predict3 = predict3/np.std(predict3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check corelation of observed rmm1 and model prediction over 1979-2008 while using pressure from 1946-2008 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm = len(xtest3)-len(test_x3)+ window\n",
    "itx = x_test3[window:rm].index ## We are using 120 days running mean as input so first 120 values should be ignored\n",
    "#As stacked LSTM is used with batch size of 50, so input and output should have timeseries that divided by 50, so we ignored last 148 values for round off \n",
    "rmm1_46_15 = pd.DataFrame(predict3,index = itx)\n",
    "\n",
    "plt.plot(rmm1_46_15.loc[y_train.index,:],y_train,\"+\")\n",
    "corr  = np.corrcoef(rmm1_46_15.loc[y_train.index,:],y_train)[0,1]\n",
    "plt.title('correlation netween oliver and LSTM = %f'%corr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relation with Oliver Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/cccr/supriyo/panini/data/rmm_oliver.csv')\n",
    "df['date'] = df.year.map(str)+'-'+df.month.map(str)+'-'+df.day.map(str)\n",
    "df.date = pd.to_datetime(df.date)\n",
    "df.index = df.date\n",
    "r1 = df.loc['1947-1-1':'2008-12-31','IHR1'].values\n",
    "r2 = rmm1_46_15.loc['1947-1-1':'2008-12-31'].values.squeeze()\n",
    "\n",
    "corr = np.corrcoef(r1,r2)[0,1]\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize = (14,5))\n",
    "ax[0].scatter(r1,r2)\n",
    "ax[0].set_title('correlation netween oliver and LSTM = %f'%corr)\n",
    "bins = np.linspace(-4.0,4.0,41)\n",
    "\n",
    "ax[1].hist(r1,bins,alpha=0.5,label='lstm')\n",
    "ax[1].hist(r2,bins,alpha = 0.5,label='oliver')\n",
    "ax[1].axvline(0.0,color='r')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "RMM1         = rmm1_46_15*1\n",
    "RMM1.columns = ['rmm1']\n",
    "RMM1.to_csv('rmm1_prediction_46-15_minmax_new_filt.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.figure(figsize = (20,8))\n",
    "plt.plot(RMM1.loc[y_test.index][0:800],label = 'predicted LSTM RMM1')\n",
    "plt.plot(y_test[0:800],'k',label = 'original RMM1')\n",
    "# plt.plot(df.loc[y_test.index,'IHR1'][0:800],label = 'oliver RMM1')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
